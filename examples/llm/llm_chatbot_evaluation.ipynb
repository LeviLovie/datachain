{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs and RAG with DataChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LLM applications nowadays, the emerging standard pattern for most use-cases is to employ a pre-trained model with an API from a 3rd party provider and to augment it with a RAG context. On one hand, this means there is not much actual machine learning going on on the user's end. On the other hand naive application of \"latest and greatest\" models with no prompt engineering, testing and evaluation of RAG context can lead to needlessly expensive operational costs at best and dissapointingly poor performance at worst.\n",
    "\n",
    "Therefore, even if there is no machine learning involved, there is still a lot of fine tuning we need to do and a lot of that involves large datasets (such as histories of chatbot conversations or large collections of company documents). Just like with ML training, we need to version all that data as we finetune our applications to be able to correctly evaluate the effect of any changes we apply to our models. We can experiment with the LLM choice, prompt engineering, the way we process data for our RAG context (pre-processing, embedding, ...) and so on.\n",
    "\n",
    "In this example, we will see how we can use DataChain to create such a controlled development environment and how it can help us when we evaluate any fine-tuning of our LLM applications.\n",
    "\n",
    "We will see how to use DataChain to version our RAG context datasets to preserve reproducibility of our fine-tuning experiments as the RAG context changes. We will also see how to use DataChain in the evaluation of fine-tuning by comparing two different text embedding models and saving (and versioning) the results with additional context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a large collection of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we have a collection of relevant documents which we want to use as context in LLM queries in our chatbot application. We will be using DataChain to create, store and version vector embeddings of our documents.\n",
    "\n",
    "In this example we will be using papers from the [Neural Information Processing Systems](https://papers.neurips.cc/paper/) conference. \n",
    "\n",
    "We will proceed in the following steps:\n",
    "1. [Data ingestion with DataChain](#data-ingestion) - we will use DataChain to ingest the data, taking advantage of its lazy evaluation feature to only ingest the data we need\n",
    "1. [Data processing with the Unstructured Python library](#processing-the-documents-individually)\n",
    "1. [Scaling the data processing with DataChain](#processing-the-documents-at-scale-using-datachain-udfs)\n",
    "1. [Using Datachain to evaluate different embedding models](#evaluation)\n",
    "1. [Adding extra context by combining datasets](#adding-more-context---merging-datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections.abc import Iterator\n",
    "\n",
    "from datachain.lib.dc import DataChain, C\n",
    "from datachain.lib.data_model import DataModel\n",
    "from datachain.lib.file import File\n",
    "from datachain.sql.functions.array import cosine_distance, euclidean_distance\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "from unstructured.embed.huggingface import HuggingFaceEmbeddingConfig, HuggingFaceEmbeddingEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first ingest the dataset. The data are saved on a cloud storage, so we use the `.from_storage` DataChain method. We will also use the `.filter` method to restrict ourselves only to `.pdf` files (the storage contains many other data which we do not need).\n",
    "\n",
    "Notice that:\n",
    "\n",
    "1. Since DataChain employs lazy evaluation, no data are actually loaded just yet (until we invoke an action such as showing or saving our DataChain)\n",
    "1. The previous point also means that when we filter out all non-pdf files, DataChain doesn't actually waste time loading their content only to throw them away later. This makes DataChain a lot more scalable than tools with eager evaluation.\n",
    "1. The `.from_storage` method of DataChain operates on the level of the entire bucket. This means that even if the files are stored using a complicated directory structure and potentially uploaded irregularly into this structure, we can retrieve or update our DataChain of articles with just a simple one-line command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_papers = (\n",
    "    DataChain.from_storage(\"gs://datachain-demo/neurips\")\n",
    "    .filter(C.name.glob(\"*.pdf\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Listing gs://datachain-demo: 269955 objects [01:10, 3844.31 objects/s]\n",
      "Processed: 738 rows [00:00, 7876.43 rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>parent</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>etag</th>\n",
       "      <th>size</th>\n",
       "      <th>vtype</th>\n",
       "      <th>location</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>parent</th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>version</th>\n",
       "      <th>etag</th>\n",
       "      <th>is_latest</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>location</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://datachain-demo</td>\n",
       "      <td>neurips/1987/file</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf</td>\n",
       "      <td>1721047139405563</td>\n",
       "      <td>CPudi5uIqYcDEAE=</td>\n",
       "      <td>2291566</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>gs://datachain-demo</td>\n",
       "      <td>neurips/1987/file</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf</td>\n",
       "      <td>2291566</td>\n",
       "      <td>1721047139405563</td>\n",
       "      <td>CPudi5uIqYcDEAE=</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://datachain-demo</td>\n",
       "      <td>neurips/1987/file</td>\n",
       "      <td>03afdbd66e7929b125f8597834fa83a4-Paper.pdf</td>\n",
       "      <td>1721047138865046</td>\n",
       "      <td>CJaf6pqIqYcDEAE=</td>\n",
       "      <td>1322648</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>gs://datachain-demo</td>\n",
       "      <td>neurips/1987/file</td>\n",
       "      <td>03afdbd66e7929b125f8597834fa83a4-Paper.pdf</td>\n",
       "      <td>1322648</td>\n",
       "      <td>1721047138865046</td>\n",
       "      <td>CJaf6pqIqYcDEAE=</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://datachain-demo</td>\n",
       "      <td>neurips/1987/file</td>\n",
       "      <td>072b030ba126b2f4b2374f342be9ed44-Paper.pdf</td>\n",
       "      <td>1721046993295769</td>\n",
       "      <td>CJmztdWHqYcDEAE=</td>\n",
       "      <td>1220711</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>gs://datachain-demo</td>\n",
       "      <td>neurips/1987/file</td>\n",
       "      <td>072b030ba126b2f4b2374f342be9ed44-Paper.pdf</td>\n",
       "      <td>1220711</td>\n",
       "      <td>1721046993295769</td>\n",
       "      <td>CJmztdWHqYcDEAE=</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                source             parent  \\\n",
       "                                            \n",
       "0  gs://datachain-demo  neurips/1987/file   \n",
       "1  gs://datachain-demo  neurips/1987/file   \n",
       "2  gs://datachain-demo  neurips/1987/file   \n",
       "\n",
       "                                         name           version  \\\n",
       "                                                                  \n",
       "0  02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf  1721047139405563   \n",
       "1  03afdbd66e7929b125f8597834fa83a4-Paper.pdf  1721047138865046   \n",
       "2  072b030ba126b2f4b2374f342be9ed44-Paper.pdf  1721046993295769   \n",
       "\n",
       "               etag     size vtype location                 file  \\\n",
       "                                                          source   \n",
       "0  CPudi5uIqYcDEAE=  2291566           None  gs://datachain-demo   \n",
       "1  CJaf6pqIqYcDEAE=  1322648           None  gs://datachain-demo   \n",
       "2  CJmztdWHqYcDEAE=  1220711           None  gs://datachain-demo   \n",
       "\n",
       "                file                                        file     file  \\\n",
       "              parent                                        name     size   \n",
       "0  neurips/1987/file  02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf  2291566   \n",
       "1  neurips/1987/file  03afdbd66e7929b125f8597834fa83a4-Paper.pdf  1322648   \n",
       "2  neurips/1987/file  072b030ba126b2f4b2374f342be9ed44-Paper.pdf  1220711   \n",
       "\n",
       "               file              file      file                      file  \\\n",
       "            version              etag is_latest             last_modified   \n",
       "0  1721047139405563  CPudi5uIqYcDEAE=         1 1970-01-01 00:00:00+00:00   \n",
       "1  1721047138865046  CJaf6pqIqYcDEAE=         1 1970-01-01 00:00:00+00:00   \n",
       "2  1721046993295769  CJmztdWHqYcDEAE=         1 1970-01-01 00:00:00+00:00   \n",
       "\n",
       "      file  file  \n",
       "  location vtype  \n",
       "0     None        \n",
       "1     None        \n",
       "2     None        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Limited by 3 rows]\n"
     ]
    }
   ],
   "source": [
    "dc_papers.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataChain created a record for each `pdf` file in the `neurips` directory, generating a `file` signal for each file. The file signal contains subsignals with metadata about each file, like `file.name` and `file.size`. Aggregate signals like `file` that contain multiple subsignals are called features.\n",
    "\n",
    "You can use the `file` feature to not only get metadata about each file, but also to open and read the file as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the documents individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to ingest the content of the pdf files as text, divide it into chunks and vectorize those for our RAG application. We are interested in comparing two different models for embeddings. Normally, we would also do some pre-processing and cleaning of the text before vectorization, but we will skip it here for brevity.\n",
    "\n",
    "We will first do all this with an example of a single pdf using the `unstructured` Python library and then we will see how we can scale this up to the entire bucket with the help of DataChain.\n",
    "\n",
    "First, we ingest and partition the pdf file and chunk it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_by_title(partition_pdf(filename=\"sample.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we vectorize each chunk using HuggingFace embedding encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding encoder\n",
    "\n",
    "embedding_encoder = HuggingFaceEmbeddingEncoder(\n",
    "     config=HuggingFaceEmbeddingConfig()\n",
    ")\n",
    "\n",
    "embedding_encoder_alt = HuggingFaceEmbeddingEncoder(\n",
    "     config=HuggingFaceEmbeddingConfig(model_name='intfloat/e5-small-v2')\n",
    ")\n",
    "\n",
    "chunks_embedded = embedding_encoder.embed_documents(chunks)\n",
    "chunks_embedded_alt = embedding_encoder_alt.embed_documents(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our chunks vectorized and ready for comparison (e.g. with cosine similarity). However, we are missing a few ingredients:\n",
    "\n",
    "1. ***Scaling*** - we only processed a single pdf file and we had to manually specify its path. We need to find a way to process all our documents at scale instead and to save the results.\n",
    "2. ***Saving and Versioning*** - even if we only had a single or a few PDF files we would like to use in our RAG, it is a good practice to version the outputs so that we can keep track of and fine-tune our RAG application. If we simply save the current results to a bucket and overwrite it each time the source is updated, we lose this. We could version the results manually, e.g. by adding a timestamp to the blob name, but that is not very reliable and will lead to unnecessary copies of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the documents at scale, using DataChain UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use DataChain to solve the scaling and versioning issues we outline above. We will create a DataChain user-defined function (UDF) to process all our PDF files the way we did above with a single file (without us having to manually provide file paths) and save the outputs in a Datachain.\n",
    "\n",
    "The DataChain UDF functionality will allow us to generate additonal columns in our DataChain, iterating over each of the files listed in it.\n",
    "\n",
    "We first need to define a DataModel class, which will define the types of our outputs. Inputs and outputs need to be specified like this when we use custom functinos in Datachain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output as a Feature class\n",
    "class Chunk(DataModel):\n",
    "    key: str\n",
    "    text: str\n",
    "    embeddings: list[float]\n",
    "    embeddings_alt: list[float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we define `Chunk` by specifying the names and types of new columns on the output.\n",
    "\n",
    "We then define our processing function `pdf_chuks`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use signatures to define input/output types (these can be Feature or regular Python types)\n",
    "def pdf_chunks(file: File) -> Iterator[Chunk]:\n",
    "    # Ingest the file\n",
    "    with file.open() as f:\n",
    "        chunks = chunk_by_title(partition_pdf(file=f))\n",
    "\n",
    "    chunks_embedded = embedding_encoder.embed_documents(chunks)\n",
    "    chunks_embedded_alt = embedding_encoder_alt.embed_documents(chunks)\n",
    "\n",
    "    # Add new rows to DataChain\n",
    "    for chunk, chunk_alt in zip(chunks_embedded, chunks_embedded_alt):\n",
    "        record = {}\n",
    "        record[\"key\"] = file.name.removesuffix(\"-Paper.pdf\")\n",
    "        record[\"text\"] = chunk.text\n",
    "        record[\"embeddings\"] = chunk.embeddings\n",
    "        record[\"embeddings_alt\"] = chunk_alt.embeddings\n",
    "\n",
    "        yield Chunk(**record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the syntax is the same as with any other Python function, except that we specify the input and output types using type hints\n",
    "\n",
    "```\n",
    "def pdf_chunks(file: File) -> Iterator[Chunk]:\n",
    "```\n",
    "Here, `file` specifies that we pass all `file` columns of the original dataset on the input and `Iterator[Chunk]` specifies that we get a bunch of `Chunk` rows on the output (from a single row of the original datachain representing a single paper we will get a new dataset with multiple rows per paper, each representing a single chunk).\n",
    "\n",
    "We then specify what each row should contain by defining the `record` dictionary and then we use `yield Chunk(**record)` to create the new rows for each input row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 738 rows [00:00, 9790.32 rows/s]\n",
      "Processed: 0 rows [00:00, ? rows/s]\n",
      "Processed: 2 rows [00:06,  3.33s/ rows]\n",
      "Processed: 3 rows [00:12,  4.36s/ rows]\n",
      "Processed: 4 rows [00:17,  4.76s/ rows]\n",
      "Processed: 5 rows [00:26,  5.95s/ rows]\n",
      "Processed: 6 rows [00:32,  6.01s/ rows]\n",
      "Processed: 7 rows [00:37,  5.81s/ rows]\n",
      "Processed: 8 rows [00:44,  6.08s/ rows]\n",
      "Processed: 9 rows [00:52,  6.61s/ rows]\n",
      "Processed: 10 rows [00:58,  6.65s/ rows]\n",
      "Processed: 11 rows [01:09,  7.89s/ rows]\n",
      "Processed: 12 rows [01:16,  7.70s/ rows]\n",
      "Processed: 13 rows [01:22,  6.98s/ rows]\n",
      "Processed: 14 rows [01:28,  6.70s/ rows]\n",
      "Processed: 15 rows [01:32,  6.05s/ rows]\n",
      "Processed: 16 rows [01:39,  6.27s/ rows]\n",
      "Processed: 17 rows [01:44,  5.91s/ rows]\n",
      "Processed: 18 rows [01:49,  5.56s/ rows]\n",
      "Processed: 19 rows [01:57,  6.24s/ rows]\n",
      "Processed: 20 rows [02:04,  6.63s/ rows]\n",
      "Download: 51.2MB [02:10, 413kB/s]\n",
      "Processed: 20 rows [02:10,  6.53s/ rows]\n",
      "Generated: 1346 rows [02:03, 10.86 rows/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datachain.lib.dc.DataChain at 0x7f7a239eacf0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_chunks_embeddings = (\n",
    "    dc_papers\n",
    "    .limit(20) # we limit ourselves to 20 papers here, to speed up the demo\n",
    "    .gen(document=pdf_chunks)\n",
    ")\n",
    "\n",
    "dc_chunks_embeddings.save(\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above we apply our new `pdf_chunks` function to the DataChain `dc_papers`. We do that by using the `gen` method of DataChain with `pdf_chunks`as its parameter. \n",
    "\n",
    "`DataChain.gen` is used when we have a function that creates multiple rows per single row of the original datachain (like in our examples, where each paper is split into multiple chunks)\n",
    "\n",
    "We also presisted the result by the `.save` method. This will permanently save and version the datachain as a dataset with the name `embeddings`. Whenever we call `.save(\"embeddings\")` again, a new version of this dataset will be saved automatically, so we can recall previous versions and track changes of the dataset over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use DataChain to calculate the similarity between the two alternative embeddings of each chunk and for further evaluation we will save dataset containing the chunks that differ the most between the two embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we saved our dataset `embeddings`, we can now load its content to datachain by the `from_dataset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>573\\n\\nBIT - SERIAL NEURAL NETWORKS\\n\\nAlan F....</td>\n",
       "      <td>[-0.071039117872715, 0.018864696845412254, 0.0...</td>\n",
       "      <td>[-0.071039117872715, 0.018864696845412254, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>A bit - serial VLSI neural network is describe...</td>\n",
       "      <td>[-0.0730624571442604, 0.03725254908204079, 0.0...</td>\n",
       "      <td>[-0.0730624571442604, 0.03725254908204079, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>nique is extended to a 256 (2562 synapses) net...</td>\n",
       "      <td>[-0.05953378230333328, 0.013371129520237446, 0...</td>\n",
       "      <td>[-0.05953378230333328, 0.013371129520237446, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>1. INTRODUCTION The functions a synthetic neur...</td>\n",
       "      <td>[-0.08661094307899475, 0.006553625222295523, 0...</td>\n",
       "      <td>[-0.08661094307899475, 0.006553625222295523, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>yield, where the network degradation is approx...</td>\n",
       "      <td>[-0.07803991436958313, 0.011682862415909767, 0...</td>\n",
       "      <td>[-0.07803991436958313, 0.011682862415909767, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           document  \\\n",
       "                                key   \n",
       "0  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "1  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "2  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "3  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "4  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "\n",
       "                                                      \\\n",
       "                                                text   \n",
       "0  573\\n\\nBIT - SERIAL NEURAL NETWORKS\\n\\nAlan F....   \n",
       "1  A bit - serial VLSI neural network is describe...   \n",
       "2  nique is extended to a 256 (2562 synapses) net...   \n",
       "3  1. INTRODUCTION The functions a synthetic neur...   \n",
       "4  yield, where the network degradation is approx...   \n",
       "\n",
       "                                                      \\\n",
       "                                          embeddings   \n",
       "0  [-0.071039117872715, 0.018864696845412254, 0.0...   \n",
       "1  [-0.0730624571442604, 0.03725254908204079, 0.0...   \n",
       "2  [-0.05953378230333328, 0.013371129520237446, 0...   \n",
       "3  [-0.08661094307899475, 0.006553625222295523, 0...   \n",
       "4  [-0.07803991436958313, 0.011682862415909767, 0...   \n",
       "\n",
       "                                                      \n",
       "                                      embeddings_alt  \n",
       "0  [-0.071039117872715, 0.018864696845412254, 0.0...  \n",
       "1  [-0.0730624571442604, 0.03725254908204079, 0.0...  \n",
       "2  [-0.05953378230333328, 0.013371129520237446, 0...  \n",
       "3  [-0.08661094307899475, 0.006553625222295523, 0...  \n",
       "4  [-0.07803991436958313, 0.011682862415909767, 0...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    DataChain.from_dataset(\"embeddings\")\n",
    "    .mutate(\n",
    "        my_new_column = C.document.embeddings * 2\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>573\\n\\nBIT - SERIAL NEURAL NETWORKS\\n\\nAlan F....</td>\n",
       "      <td>[-0.071039117872715, 0.018864696845412254, 0.0...</td>\n",
       "      <td>[-0.071039117872715, 0.018864696845412254, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>A bit - serial VLSI neural network is describe...</td>\n",
       "      <td>[-0.0730624571442604, 0.03725254908204079, 0.0...</td>\n",
       "      <td>[-0.0730624571442604, 0.03725254908204079, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>nique is extended to a 256 (2562 synapses) net...</td>\n",
       "      <td>[-0.05953378230333328, 0.013371129520237446, 0...</td>\n",
       "      <td>[-0.05953378230333328, 0.013371129520237446, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>1. INTRODUCTION The functions a synthetic neur...</td>\n",
       "      <td>[-0.08661094307899475, 0.006553625222295523, 0...</td>\n",
       "      <td>[-0.08661094307899475, 0.006553625222295523, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "      <td>yield, where the network degradation is approx...</td>\n",
       "      <td>[-0.07803991436958313, 0.011682862415909767, 0...</td>\n",
       "      <td>[-0.07803991436958313, 0.011682862415909767, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           document  \\\n",
       "                                key   \n",
       "0  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "1  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "2  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "3  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "4  02e74f10e0327ad868d138f2b4fdd6f0   \n",
       "\n",
       "                                                      \\\n",
       "                                                text   \n",
       "0  573\\n\\nBIT - SERIAL NEURAL NETWORKS\\n\\nAlan F....   \n",
       "1  A bit - serial VLSI neural network is describe...   \n",
       "2  nique is extended to a 256 (2562 synapses) net...   \n",
       "3  1. INTRODUCTION The functions a synthetic neur...   \n",
       "4  yield, where the network degradation is approx...   \n",
       "\n",
       "                                                      \\\n",
       "                                          embeddings   \n",
       "0  [-0.071039117872715, 0.018864696845412254, 0.0...   \n",
       "1  [-0.0730624571442604, 0.03725254908204079, 0.0...   \n",
       "2  [-0.05953378230333328, 0.013371129520237446, 0...   \n",
       "3  [-0.08661094307899475, 0.006553625222295523, 0...   \n",
       "4  [-0.07803991436958313, 0.011682862415909767, 0...   \n",
       "\n",
       "                                                      \n",
       "                                      embeddings_alt  \n",
       "0  [-0.071039117872715, 0.018864696845412254, 0.0...  \n",
       "1  [-0.0730624571442604, 0.03725254908204079, 0.0...  \n",
       "2  [-0.05953378230333328, 0.013371129520237446, 0...  \n",
       "3  [-0.08661094307899475, 0.006553625222295523, 0...  \n",
       "4  [-0.07803991436958313, 0.011682862415909767, 0...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate similarity\n",
    "\n",
    "(\n",
    "    DataChain.from_dataset(\"embeddings\")\n",
    "    .mutate(\n",
    "        test = C.document.embeddings * 2,\n",
    "        this_should_fail=cosine_distance([2,3,3,4,5], C(\"document.embeddings_alt\")),\n",
    "        cos_dist=cosine_distance(C(\"document.embeddings\"), C(\"document.embeddings_alt\")),\n",
    "        eucl_dist=euclidean_distance(C(\"document.embeddings\"), C(\"document.embeddings_alt\")),\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .head()\n",
    "    # .save(\"embeddings-differences\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we use the `cosine_distance` and `euclidean_distance` Datachain built-in functions to calculate the similarity between the two embeddings for each chunk. To specify that we want to compare columns we use the `C` class from `datachain.lib.dc`.\n",
    "\n",
    "We use the `mutate` method of datachain, which is a way to add new columns to an existing dataset. Finally we use the `.save` method once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>document</th>\n",
       "      <th>document</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_alt</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573\\n\\nBIT - SERIAL NEURAL NETWORKS\\n\\nAlan F....</td>\n",
       "      <td>[-0.071039117872715, 0.018864696845412254, 0.0...</td>\n",
       "      <td>[-0.071039117872715, 0.018864696845412254, 0.0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A bit - serial VLSI neural network is describe...</td>\n",
       "      <td>[-0.0730624571442604, 0.03725254908204079, 0.0...</td>\n",
       "      <td>[-0.0730624571442604, 0.03725254908204079, 0.0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nique is extended to a 256 (2562 synapses) net...</td>\n",
       "      <td>[-0.05953378230333328, 0.013371129520237446, 0...</td>\n",
       "      <td>[-0.05953378230333328, 0.013371129520237446, 0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. INTRODUCTION The functions a synthetic neur...</td>\n",
       "      <td>[-0.08661094307899475, 0.006553625222295523, 0...</td>\n",
       "      <td>[-0.08661094307899475, 0.006553625222295523, 0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yield, where the network degradation is approx...</td>\n",
       "      <td>[-0.07803991436958313, 0.011682862415909767, 0...</td>\n",
       "      <td>[-0.07803991436958313, 0.011682862415909767, 0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>states and represents the learned information ...</td>\n",
       "      <td>[-0.09751544147729874, 0.034578703343868256, 0...</td>\n",
       "      <td>[-0.09751544147729874, 0.034578703343868256, 0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XI\\n\\n••••\\n\\ni-n-l 0 ~ ii J-O\\n\\n(2)\\n\\nwhere...</td>\n",
       "      <td>[-0.12508268654346466, 0.04674600064754486, 0....</td>\n",
       "      <td>[-0.12508268654346466, 0.04674600064754486, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a large number of interconnects. The challenge...</td>\n",
       "      <td>[-0.07087741047143936, 0.02634391188621521, 0....</td>\n",
       "      <td>[-0.07087741047143936, 0.02634391188621521, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2. DESIGNING A NEURAL NETWORK IN VLSI There ar...</td>\n",
       "      <td>[-0.07934948056936264, 0.04542921110987663, 0....</td>\n",
       "      <td>[-0.07934948056936264, 0.04542921110987663, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>therefore possible without recourse to unusual...</td>\n",
       "      <td>[-0.09430072456598282, 0.029243627563118935, -...</td>\n",
       "      <td>[-0.09430072456598282, 0.029243627563118935, -...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>giving a low synapse count on a single chip. T...</td>\n",
       "      <td>[-0.105259969830513, 0.008684634231030941, 0.0...</td>\n",
       "      <td>[-0.105259969830513, 0.008684634231030941, 0.0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>developing neural chips and boards, and the fo...</td>\n",
       "      <td>[-0.08238476514816284, 0.023592669516801834, 0...</td>\n",
       "      <td>[-0.08238476514816284, 0.023592669516801834, 0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>regime [5,6]. The problem of implementing anal...</td>\n",
       "      <td>[-0.10331474989652634, 0.03557790070772171, 0....</td>\n",
       "      <td>[-0.10331474989652634, 0.03557790070772171, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tightly pipelined arithmetic structures. It is...</td>\n",
       "      <td>[-0.08724997937679291, 0.039673104882240295, -...</td>\n",
       "      <td>[-0.08724997937679291, 0.039673104882240295, -...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>this paper, we are developing a hybrid analOg/...</td>\n",
       "      <td>[-0.09496001899242401, 0.021780485287308693, 0...</td>\n",
       "      <td>[-0.09496001899242401, 0.021780485287308693, 0...</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>schematically in figure 1. Neurons are represe...</td>\n",
       "      <td>[-0.07906163483858109, 0.0343417152762413, -0....</td>\n",
       "      <td>[-0.07906163483858109, 0.0343417152762413, -0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>function is therefore to multiply the signalli...</td>\n",
       "      <td>[-0.10236826539039612, 0.05182984843850136, 0....</td>\n",
       "      <td>[-0.10236826539039612, 0.05182984843850136, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Synapse\\n\\nStates { Vj }\\n\\nNeurons\\n\\nFigure ...</td>\n",
       "      <td>[-0.0865655392408371, 0.012793723493814468, 0....</td>\n",
       "      <td>[-0.0865655392408371, 0.012793723493814468, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This type of architecture has many attractions...</td>\n",
       "      <td>[-0.0694190189242363, 0.023230072110891342, 0....</td>\n",
       "      <td>[-0.0694190189242363, 0.023230072110891342, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>indicate their state by the presence or absenc...</td>\n",
       "      <td>[-0.09249333292245865, 0.03475728631019592, 0....</td>\n",
       "      <td>[-0.09249333292245865, 0.03475728631019592, 0....</td>\n",
       "      <td>02e74f10e0327ad868d138f2b4fdd6f0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             document  \\\n",
       "                                                 text   \n",
       "0   573\\n\\nBIT - SERIAL NEURAL NETWORKS\\n\\nAlan F....   \n",
       "1   A bit - serial VLSI neural network is describe...   \n",
       "2   nique is extended to a 256 (2562 synapses) net...   \n",
       "3   1. INTRODUCTION The functions a synthetic neur...   \n",
       "4   yield, where the network degradation is approx...   \n",
       "5   states and represents the learned information ...   \n",
       "6   XI\\n\\n••••\\n\\ni-n-l 0 ~ ii J-O\\n\\n(2)\\n\\nwhere...   \n",
       "7   a large number of interconnects. The challenge...   \n",
       "8   2. DESIGNING A NEURAL NETWORK IN VLSI There ar...   \n",
       "9   therefore possible without recourse to unusual...   \n",
       "10  giving a low synapse count on a single chip. T...   \n",
       "11  developing neural chips and boards, and the fo...   \n",
       "12  regime [5,6]. The problem of implementing anal...   \n",
       "13  tightly pipelined arithmetic structures. It is...   \n",
       "14  this paper, we are developing a hybrid analOg/...   \n",
       "15  schematically in figure 1. Neurons are represe...   \n",
       "16  function is therefore to multiply the signalli...   \n",
       "17  Synapse\\n\\nStates { Vj }\\n\\nNeurons\\n\\nFigure ...   \n",
       "18  This type of architecture has many attractions...   \n",
       "19  indicate their state by the presence or absenc...   \n",
       "\n",
       "                                             document  \\\n",
       "                                           embeddings   \n",
       "0   [-0.071039117872715, 0.018864696845412254, 0.0...   \n",
       "1   [-0.0730624571442604, 0.03725254908204079, 0.0...   \n",
       "2   [-0.05953378230333328, 0.013371129520237446, 0...   \n",
       "3   [-0.08661094307899475, 0.006553625222295523, 0...   \n",
       "4   [-0.07803991436958313, 0.011682862415909767, 0...   \n",
       "5   [-0.09751544147729874, 0.034578703343868256, 0...   \n",
       "6   [-0.12508268654346466, 0.04674600064754486, 0....   \n",
       "7   [-0.07087741047143936, 0.02634391188621521, 0....   \n",
       "8   [-0.07934948056936264, 0.04542921110987663, 0....   \n",
       "9   [-0.09430072456598282, 0.029243627563118935, -...   \n",
       "10  [-0.105259969830513, 0.008684634231030941, 0.0...   \n",
       "11  [-0.08238476514816284, 0.023592669516801834, 0...   \n",
       "12  [-0.10331474989652634, 0.03557790070772171, 0....   \n",
       "13  [-0.08724997937679291, 0.039673104882240295, -...   \n",
       "14  [-0.09496001899242401, 0.021780485287308693, 0...   \n",
       "15  [-0.07906163483858109, 0.0343417152762413, -0....   \n",
       "16  [-0.10236826539039612, 0.05182984843850136, 0....   \n",
       "17  [-0.0865655392408371, 0.012793723493814468, 0....   \n",
       "18  [-0.0694190189242363, 0.023230072110891342, 0....   \n",
       "19  [-0.09249333292245865, 0.03475728631019592, 0....   \n",
       "\n",
       "                                             document  \\\n",
       "                                       embeddings_alt   \n",
       "0   [-0.071039117872715, 0.018864696845412254, 0.0...   \n",
       "1   [-0.0730624571442604, 0.03725254908204079, 0.0...   \n",
       "2   [-0.05953378230333328, 0.013371129520237446, 0...   \n",
       "3   [-0.08661094307899475, 0.006553625222295523, 0...   \n",
       "4   [-0.07803991436958313, 0.011682862415909767, 0...   \n",
       "5   [-0.09751544147729874, 0.034578703343868256, 0...   \n",
       "6   [-0.12508268654346466, 0.04674600064754486, 0....   \n",
       "7   [-0.07087741047143936, 0.02634391188621521, 0....   \n",
       "8   [-0.07934948056936264, 0.04542921110987663, 0....   \n",
       "9   [-0.09430072456598282, 0.029243627563118935, -...   \n",
       "10  [-0.105259969830513, 0.008684634231030941, 0.0...   \n",
       "11  [-0.08238476514816284, 0.023592669516801834, 0...   \n",
       "12  [-0.10331474989652634, 0.03557790070772171, 0....   \n",
       "13  [-0.08724997937679291, 0.039673104882240295, -...   \n",
       "14  [-0.09496001899242401, 0.021780485287308693, 0...   \n",
       "15  [-0.07906163483858109, 0.0343417152762413, -0....   \n",
       "16  [-0.10236826539039612, 0.05182984843850136, 0....   \n",
       "17  [-0.0865655392408371, 0.012793723493814468, 0....   \n",
       "18  [-0.0694190189242363, 0.023230072110891342, 0....   \n",
       "19  [-0.09249333292245865, 0.03475728631019592, 0....   \n",
       "\n",
       "                            document  \n",
       "                                 key  \n",
       "0   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "1   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "2   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "3   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "4   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "5   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "6   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "7   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "8   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "9   02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "10  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "11  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "12  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "13  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "14  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "15  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "16  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "17  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "18  02e74f10e0327ad868d138f2b4fdd6f0  \n",
       "19  02e74f10e0327ad868d138f2b4fdd6f0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Limited by 20 rows]\n"
     ]
    }
   ],
   "source": [
    "DataChain.from_dataset(\"embeddings-differences\").order_by(C.cos_dist).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now solved our scalability issues. When using `DataChain` locally, our computation will still be restricted to a simgle machine but for larger datasets you can use the SaaS version of DataChain available through our DVC Studio which comes with automatic computation cluster management, a graphical user interface and additional ML and data versioning features.\n",
    "\n",
    "We have also solved our versioning needs and we can track the differences between embeddings over time and use that to choose the best embedding for our use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more context - merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example bucket, we have not only the `pdf` files themselves but also additinal metadata stored as JSON files. We will now see how we can use Datachain to add the information about authors and the paper title to our `embeddings-differences` dataset which can help us with our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'given_name': 'Alan', 'family_name': 'Murray', 'institution': None},\n",
       " {'given_name': 'Anthony', 'family_name': 'Smith', 'institution': None},\n",
       " {'given_name': 'Zoe', 'family_name': 'Butler', 'institution': None}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "meta = json.load(open(\"sample.json\"))\n",
    "meta[\"authors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the metadata contains information about the authors of the paper as a list of dictionaries with each author's name ane institution. Some values can be also be empty. Just as above we create a `DataModel` class to specify the outputs, keeping the name of the file as a key which we will use to join with the previous dataset.\n",
    "\n",
    "Then we create a function to parse all this information and create a new dataset. We will now only create a single row per original dataset, so we use `return` instead of yield (and there is no need for the `Iterator` class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output as a Feature class\n",
    "class Metadata(DataModel):\n",
    "    key: str\n",
    "    title: str\n",
    "    authors: list[dict[str, Optional[str]]]\n",
    "\n",
    "\n",
    "# Use signatures to define input/output types (these can be Feature or regular Python types)\n",
    "def extract_metadata(file: File) -> Metadata:\n",
    "    import json\n",
    "    # Ingest the file\n",
    "    metadata = json.loads(file.get_value())\n",
    "\n",
    "    record = dict()\n",
    "    record[\"filename\"] = file.name.removesuffix(\"Metadata.json\")+\"Paper.pdf\"\n",
    "    record[\"title\"] = metadata[\"title\"]\n",
    "    record[\"authors\"] = metadata[\"authors\"]\n",
    "\n",
    "    return Metadata(**record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the `extract_metadata` function as we did with `pdf_chunks` above, except that we use the `.map` method of DataChain which is employed when there is a 1:1 correspondence between the number of rows of the orignal and the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 738 rows [00:00, 19701.34 rows/s]\n",
      "Download: 0.00B [00:00, ?B/s]Traceback (most recent call last):\n",
      "  File \"/home/tibor/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/udf.py\", line 109, in process\n",
      "    return self._func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23662/3412983646.py\", line 19, in extract_metadata\n",
      "    return Metadata(**record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tibor/Repos/datachain/.venv/lib64/python3.12/site-packages/pydantic/main.py\", line 193, in __init__\n",
      "    self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "pydantic_core._pydantic_core.ValidationError: 1 validation error for Metadata\n",
      "key\n",
      "  Field required [type=missing, input_value={'filename': '02e74f10e03..., 'institution': None}]}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/missing\n",
      "Download: 30.1kB [00:00, 15.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Error in user code: 'Mapper' ==============\n",
      "==========================================================\n"
     ]
    },
    {
     "ename": "DataChainError",
     "evalue": "Error in user code in class 'Mapper': 1 validation error for Metadata\nkey\n  Field required [type=missing, input_value={'filename': '02e74f10e03..., 'institution': None}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataChainError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m dc_meta \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     DataChain\u001b[38;5;241m.\u001b[39mfrom_storage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://datachain-demo/neurips\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter(C\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*Metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      6\u001b[0m (\n\u001b[1;32m      7\u001b[0m     \u001b[43mdc_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument.key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument.title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument.authors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/dc.py:749\u001b[0m, in \u001b[0;36mDataChain.show\u001b[0;34m(self, limit, flatten, transpose)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     dc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit(limit) \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 749\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[1;32m    751\u001b[0m         df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/dc.py:743\u001b[0m, in \u001b[0;36mDataChain.to_pandas\u001b[0;34m(self, flatten)\u001b[0m\n\u001b[1;32m    740\u001b[0m         df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, header)) \u001b[38;5;28;01mfor\u001b[39;00m header \u001b[38;5;129;01min\u001b[39;00m headers]\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m--> 743\u001b[0m transposed_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[1;32m    744\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mtuple\u001b[39m(n): val \u001b[38;5;28;01mfor\u001b[39;00m n, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(headers, transposed_result)}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/dc.py:564\u001b[0m, in \u001b[0;36mDataChain.results\u001b[0;34m(self, row_factory, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     db_signals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignals_schema\u001b[38;5;241m.\u001b[39mdb_signals()\n\u001b[1;32m    563\u001b[0m     rows \u001b[38;5;241m=\u001b[39m (row_factory(db_signals, r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rows)\n\u001b[0;32m--> 564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/dc.py:554\u001b[0m, in \u001b[0;36mDataChain.iterate_flatten\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate_flatten\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mtuple\u001b[39m[Any]]:\n\u001b[1;32m    553\u001b[0m     db_signals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignals_schema\u001b[38;5;241m.\u001b[39mdb_signals()\n\u001b[0;32m--> 554\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdb_signals\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/query/dataset.py:1236\u001b[0m, in \u001b[0;36mDatasetQuery.as_iterable\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_iterable\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ResultIter]:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1236\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mselect()\n\u001b[1;32m   1237\u001b[0m         selected_columns \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m query\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m ResultIter(\n\u001b[1;32m   1239\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcatalog\u001b[38;5;241m.\u001b[39mwarehouse\u001b[38;5;241m.\u001b[39mdataset_rows_select(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m   1240\u001b[0m             selected_columns,\n\u001b[1;32m   1241\u001b[0m         )\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/query/dataset.py:1179\u001b[0m, in \u001b[0;36mDatasetQuery.apply_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m         group_by \u001b[38;5;241m=\u001b[39m step\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1179\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_table_names\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# a chain of steps linked by results\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies\u001b[38;5;241m.\u001b[39mupdate(result\u001b[38;5;241m.\u001b[39mdependencies)\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group_by:\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/query/dataset.py:631\u001b[0m, in \u001b[0;36mUDF.apply\u001b[0;34m(self, query_generator, temp_tables)\u001b[0m\n\u001b[1;32m    629\u001b[0m udf_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_udf_table(_query)\n\u001b[1;32m    630\u001b[0m temp_tables\u001b[38;5;241m.\u001b[39mappend(udf_table\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_udf_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mudf_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m q, cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_result_query(udf_table, query)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_result(q, cols)\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/query/dataset.py:549\u001b[0m, in \u001b[0;36mUDF.populate_udf_table\u001b[0;34m(self, udf_table, query)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m     udf_results \u001b[38;5;241m=\u001b[39m udf\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    542\u001b[0m         udf_inputs,\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcatalog,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         processed_cb,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m     \u001b[43mprocess_udf_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarehouse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerated_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     download_cb\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/query/dataset.py:396\u001b[0m, in \u001b[0;36mprocess_udf_outputs\u001b[0;34m(warehouse, udf_table, udf_results, udf, batch_size, cb)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Optimization: Compute row types once, rather than for every row.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m udf_col_types \u001b[38;5;241m=\u001b[39m get_udf_col_types(warehouse, udf)\n\u001b[0;32m--> 396\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mudf_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mudf_results\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mudf_output\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/udf.py:58\u001b[0m, in \u001b[0;36mUDFAdapter.run\u001b[0;34m(self, udf_inputs, catalog, is_generator, cache, download_cb, processed_cb)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m udf_inputs:\n\u001b[1;32m     57\u001b[0m     n_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch\u001b[38;5;241m.\u001b[39mrows) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, RowBatch) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 58\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     processed_cb\u001b[38;5;241m.\u001b[39mrelative_update(n_rows)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/udf.py:82\u001b[0m, in \u001b[0;36mUDFAdapter.run_once\u001b[0;34m(self, catalog, arg, is_generator, cache, cb)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, RowDict):\n\u001b[1;32m     81\u001b[0m     udf_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_parameters(catalog, arg, cache\u001b[38;5;241m=\u001b[39mcache, cb\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m---> 82\u001b[0m     udf_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mudf_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_cb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_generator:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;66;03m# udf_outputs is generator already if is_generator=True\u001b[39;00m\n\u001b[1;32m     85\u001b[0m         udf_outputs \u001b[38;5;241m=\u001b[39m [udf_outputs]\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/udf.py:187\u001b[0m, in \u001b[0;36mUDFBase.__call__\u001b[0;34m(self, cache, download_cb, *rows)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_batched:\n\u001b[1;32m    185\u001b[0m     objs \u001b[38;5;241m=\u001b[39m objs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 187\u001b[0m result_objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_output_batched:\n\u001b[1;32m    190\u001b[0m     result_objs \u001b[38;5;241m=\u001b[39m [result_objs]\n",
      "File \u001b[0;32m~/Repos/datachain/.venv/lib64/python3.12/site-packages/datachain/lib/udf.py:276\u001b[0m, in \u001b[0;36mUDFBase.process_safe\u001b[0;34m(self, obj_rows)\u001b[0m\n\u001b[1;32m    274\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(exc_type, exc_value, exc_traceback\u001b[38;5;241m.\u001b[39mtb_next)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(msg))\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataChainError(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in user code in class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_objs\n",
      "\u001b[0;31mDataChainError\u001b[0m: Error in user code in class 'Mapper': 1 validation error for Metadata\nkey\n  Field required [type=missing, input_value={'filename': '02e74f10e03..., 'institution': None}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "source": [
    "dc_meta = (\n",
    "    DataChain.from_storage(\"gs://datachain-demo/neurips\")\n",
    "    .filter(C.name.glob(\"*Metadata.json\"))\n",
    "    )\n",
    "\n",
    "(\n",
    "    dc_meta.\n",
    "    map(document=extract_metadata)\n",
    "    .select(\n",
    "        \"document.key\",\n",
    "        \"document.title\",\n",
    "        \"document.authors\",\n",
    "    )\n",
    "    .show(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will merge the two datasets using the DataChain `.merge` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataChain.from_dataset(\"embeddings-differences\").merge(dc_meta, on=\"key\").show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
